import json
import os
import time
from data_fetcher import fetch_broad_probe_papers
from data_analyzer import analyze_one_paper

RAW_FILE = "raw_papers.json"
PROCESSED_FILE = "processed_probes.json"

def load_json(filename):
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_json(filename, data):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

def main():
    print("ğŸš€ [ETL] Starting Daily Pipeline...")

    # ================= 1. æŠ“å–é˜¶æ®µ (Fetch to Raw) =================
    raw_data = load_json(RAW_FILE)
    
    # å»ºç«‹ç´¢å¼•é˜²æ­¢é‡å¤æŠ“å–
    existing_dois = set()
    for item in raw_data:
        d = item.get('doi')
        if d: existing_dois.add(d.lower().strip().replace("https://doi.org/", ""))
    
    # çˆ¬å–è¿‡å» 5 å¤©
    print("ğŸŒ Fetching from PubMed (5 days)...")
    candidates = fetch_broad_probe_papers(days_back=5)
    
    new_raw_count = 0
    for p in candidates:
        clean_doi = p['doi'].lower().strip().replace("https://doi.org/", "")
        if clean_doi not in existing_dois:
            # åˆå§‹åŒ–çŠ¶æ€
            p['ai_analyzed'] = False 
            p['is_probe'] = False
            raw_data.append(p)
            existing_dois.add(clean_doi)
            new_raw_count += 1
            
    if new_raw_count > 0:
        print(f"ğŸ“¥ Staged {new_raw_count} new papers to {RAW_FILE}")
        save_json(RAW_FILE, raw_data)
    else:
        print("ğŸ’¤ No new raw papers found.")

    # ================= 2. åˆ†æé˜¶æ®µ (Process Pending) =================
    # æ‰¾å‡ºæ‰€æœ‰æœªåˆ†æçš„
    pending = [p for p in raw_data if not p.get('ai_analyzed')]
    print(f"â³ Pending Analysis Queue: {len(pending)} papers")
    
    if not pending:
        print("âœ… All caught up. Workflow finished.")
        return

    processed_data = load_json(PROCESSED_FILE)
    
    # æ‰¹å¤„ç†é™åˆ¶ (é˜²æ­¢ CI è¶…æ—¶)
    BATCH_SIZE = 1000 
    batch = pending[:BATCH_SIZE]
    
    analyzed_count = 0
    new_probe_count = 0

    for paper in batch:
        print(f"ğŸ¤– Analyzing: {paper['title'][:50]}...")
        try:
            result = analyze_one_paper(paper)
            
            # æ›´æ–° Raw çŠ¶æ€
            paper['ai_analyzed'] = True
            
            if result and result.get('is_new'):
                print(f"   ğŸ‰ NEW PROBE: {result.get('probe_name')}")
                paper['is_probe'] = True
                
                # å­˜å…¥æˆå“åº“ (æ¸…æ´—æ‰å†…éƒ¨çŠ¶æ€å­—æ®µ)
                final_entry = {**paper, **result}
                final_entry.pop('ai_analyzed', None)
                final_entry.pop('is_probe', None)
                processed_data.append(final_entry)
                new_probe_count += 1
            else:
                print("   âŒ Rejected (Review/App)")
                paper['is_probe'] = False
            
            analyzed_count += 1
            time.sleep(1) # Rate limit
            
        except Exception as e:
            print(f"   âš ï¸ Analysis Error: {e}")
            continue

    # ================= 3. ä¿å­˜é˜¶æ®µ =================
    if analyzed_count > 0:
        save_json(RAW_FILE, raw_data)        # æ›´æ–°çŠ¶æ€
        save_json(PROCESSED_FILE, processed_data)  # æ›´æ–°æˆå“åº“
        print(f"ğŸ’¾ Saved updates. (+{new_probe_count} probes)")

if __name__ == "__main__":
    main()