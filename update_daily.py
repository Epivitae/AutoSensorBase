import json
import os
import time
import toml
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import (
    Progress,
    SpinnerColumn,
    BarColumn,
    TextColumn,
    TimeRemainingColumn,
    MofNCompleteColumn
)
from rich.theme import Theme

# å¼•å…¥ä½ çš„ä¸šåŠ¡é€»è¾‘æ¨¡å—
from data_fetcher import fetch_broad_probe_papers
from data_analyzer import analyze_one_paper

RAW_FILE = "raw_papers.json"
PROCESSED_FILE = "processed_probes.json"

# === ðŸŸ¢ åˆå§‹åŒ– Rich Console ===
custom_theme = Theme({
    "info": "dim cyan",
    "warning": "yellow",
    "error": "bold red",
    "success": "bold green",
    "probe": "magenta"
})
console = Console(theme=custom_theme, force_terminal=True)

# ================= ðŸŸ¢ çŽ¯å¢ƒå˜é‡åŠ è½½ =================
secrets_path = ".streamlit/secrets.toml"
if os.path.exists(secrets_path):
    try:
        secrets = toml.load(secrets_path)
        if "ZHIPU_API_KEY" in secrets:
            os.environ["ZHIPU_API_KEY"] = secrets["ZHIPU_API_KEY"]
            console.print("[success]âœ… Successfully loaded API Key from secrets.toml[/]")
    except Exception as e:
        console.print(f"[error]âš ï¸ Failed to load secrets: {e}[/]")
# ===================================================

def load_json(filename):
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_json(filename, data):
    """ä¿å­˜æ•°æ®åˆ° JSON æ–‡ä»¶"""
    # ä¸ºäº†å®‰å…¨ï¼Œå¯ä»¥å…ˆå†™åˆ°ä¸´æ—¶æ–‡ä»¶å†é‡å‘½åï¼ˆå¯é€‰ï¼‰ï¼Œè¿™é‡Œä¿æŒç®€å•ç›´æŽ¥å†™
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

def normalize_doi(doi_string):
    if not doi_string: return ""
    return doi_string.lower().strip().replace("https://doi.org/", "").replace("http://doi.org/", "")

def print_stats(total, analyzed, pending, batch_size, new_fetched=0):
    """æ‰“å°æ¼‚äº®çš„ç»Ÿè®¡è¡¨æ ¼"""
    table = Table(title="ðŸ“Š Analysis Pipeline Status", show_header=True, header_style="bold magenta")
    table.add_column("Metric", style="cyan")
    table.add_column("Count", justify="right", style="green")
    table.add_column("Description", style="dim")

    table.add_row("ðŸ“š Total Papers", str(total), "Total documents in raw database")
    table.add_row("ðŸŒ Newly Fetched", str(new_fetched), "Added in this run (PubMed)")
    table.add_row("âœ… Already Analyzed", str(analyzed), "Processed in previous runs")
    table.add_row("â³ Pending Queue", str(pending), "Waiting for AI analysis")
    table.add_row("ðŸš€ Current Batch", str(batch_size), "Will be processed now")

    console.print(Panel(table, expand=False))

def main():
    console.print("[bold blue]ðŸš€ [ETL] Starting Daily Pipeline...[/]")

    # ================= 1. æŠ“å–é˜¶æ®µ =================
    raw_data = load_json(RAW_FILE)
    
    existing_raw_dois = set()
    for item in raw_data:
        existing_raw_dois.add(normalize_doi(item.get('doi')))
    
    console.print("[info]ðŸŒ Fetching from PubMed (5 days)...[/]")
    candidates = fetch_broad_probe_papers(days_back=5)
    
    new_raw_count = 0
    for p in candidates:
        clean_doi = normalize_doi(p['doi'])
        if clean_doi not in existing_raw_dois:
            p['ai_analyzed'] = False 
            p['is_probe'] = False
            raw_data.append(p)
            existing_raw_dois.add(clean_doi)
            new_raw_count += 1
            
    if new_raw_count > 0:
        console.print(f"[success]ðŸ“¥ Staged {new_raw_count} new papers to {RAW_FILE}[/]")
        save_json(RAW_FILE, raw_data)
    else:
        console.print("[dim]ðŸ’¤ No new raw papers found from fetcher.[/]")

    # ================= 2. ç»Ÿè®¡ä¸Žå‡†å¤‡ =================
    total_docs = len(raw_data)
    analyzed_docs = sum(1 for p in raw_data if p.get('ai_analyzed'))
    pending_list = [p for p in raw_data if not p.get('ai_analyzed')]
    pending_count = len(pending_list)
    
    if not pending_list:
        print_stats(total_docs, analyzed_docs, pending_count, 0, new_raw_count)
        console.print("[bold green]âœ… All caught up. Workflow finished.[/]")
        return

    processed_data = load_json(PROCESSED_FILE)
    
    processed_dois_set = set()
    for item in processed_data:
        processed_dois_set.add(normalize_doi(item.get('doi')))
    
    # è®¾å®šæ‰¹å¤„ç†å¤§å°
    BATCH_SIZE = 800 
    batch = pending_list[:BATCH_SIZE]
    
    # === ðŸ”¥ å±•ç¤ºç»Ÿè®¡é¢æ¿ ===
    print_stats(total_docs, analyzed_docs, pending_count, len(batch), new_raw_count)

    analyzed_count = 0
    new_probe_count = 0
    updated_probe_count = 0

    # ================= 3. AI åˆ†æžé˜¶æ®µ (Rich Progress) =================
    
    progress = Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]{task.description}"),
        BarColumn(),
        MofNCompleteColumn(), 
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeRemainingColumn(),
        console=console,
        expand=True
    )

    with progress:
        task_id = progress.add_task("[cyan]ðŸ¤– AI Analyzing...", total=len(batch))
        
        for paper in batch:
            title_short = paper['title'][:50] + "..." if len(paper['title']) > 50 else paper['title']
            
            try:
                result = analyze_one_paper(paper)
                
                # æ›´æ–°å†…å­˜ä¸­çš„çŠ¶æ€
                paper['ai_analyzed'] = True
                
                if result and result.get('is_new'):
                    final_entry = {**paper, **result}
                    final_entry.pop('ai_analyzed', None)
                    final_entry.pop('is_probe', None)
                    
                    current_doi = normalize_doi(paper.get('doi'))
                    probe_name = result.get('probe_name', 'Unknown')
                    
                    if current_doi in processed_dois_set:
                        # ðŸ”„ æ›´æ–°
                        console.print(f"  [warning]ðŸ”„ UPDATE:[/warning] [bold]{probe_name}[/] (Overwrite)")
                        for idx, item in enumerate(processed_data):
                            if normalize_doi(item.get('doi')) == current_doi:
                                processed_data[idx] = final_entry
                                break
                        updated_probe_count += 1
                    else:
                        # ðŸŽ‰ æ–°å¢ž
                        console.print(f"  [success]ðŸŽ‰ NEW PROBE:[/success] [bold magenta]{probe_name}[/]")
                        console.print(f"     [dim]Title: {title_short}[/]")
                        processed_data.append(final_entry)
                        processed_dois_set.add(current_doi)
                        new_probe_count += 1
                    
                    paper['is_probe'] = True
                else:
                    # console.print(f"  [dim]âŒ Rejected: {title_short}[/]") 
                    paper['is_probe'] = False
                
                analyzed_count += 1
                
                # === ðŸ’¾ å…³é”®ä¿®æ”¹ï¼šæ¯ 10 ä¸ªä¿å­˜ä¸€æ¬¡ Checkpoint ===
                if analyzed_count % 10 == 0:
                    # æ›´æ–°è¿›åº¦æ¡æè¿°è®©ç”¨æˆ·çŸ¥é“æ­£åœ¨ä¿å­˜
                    progress.update(task_id, description="[yellow]ðŸ’¾ Saving Checkpoint...[/]")
                    
                    save_json(RAW_FILE, raw_data)
                    save_json(PROCESSED_FILE, processed_data)
                    
                    # ä¿å­˜å®Œæ”¹å›žåŽŸæ¥çš„æè¿°
                    progress.update(task_id, description="[cyan]ðŸ¤– AI Analyzing...[/]")
                
                # æŽ¨è¿›è¿›åº¦æ¡
                progress.advance(task_id)
                time.sleep(1) 
                
            except Exception as e:
                console.print(f"  [error]âš ï¸ Error analyzing {title_short}: {e}[/]")
                progress.advance(task_id)
                continue

    # ================= 4. æœ€ç»ˆä¿å­˜ =================
    # å¾ªçŽ¯ç»“æŸåŽçš„æœ€åŽä¸€æ¬¡ä¿å­˜ï¼ˆé˜²æ­¢ä¸æ˜¯ 10 çš„å€æ•°æ—¶ä¸¢å¤±æœ€åŽå‡ æ¡ï¼‰
    if analyzed_count > 0:
        save_json(RAW_FILE, raw_data)
        save_json(PROCESSED_FILE, processed_data)
        
        summary_table = Table(title="ðŸ’¾ Run Summary", show_header=False, box=None)
        summary_table.add_row("Analyzed", str(analyzed_count), style="blue")
        summary_table.add_row("New Probes Found", str(new_probe_count), style="green bold")
        summary_table.add_row("Existing Updated", str(updated_probe_count), style="yellow")
        
        console.print(Panel(summary_table, title="Pipeline Completed", border_style="green"))

if __name__ == "__main__":
    main()