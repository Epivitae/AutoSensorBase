import json
import os
import time
# âœ… æ”¹åŠ¨1ï¼šå¼•å…¥æ–°çš„å¹¿åº¦ä¼˜å…ˆçˆ¬è™«å‡½æ•°
from data_fetcher import fetch_broad_probe_papers
from data_analyzer import analyze_one_paper

DB_FILE = "processed_probes.json"

def main():
    print("ğŸš€ Starting Daily Update...")

    # ================= 1. è¯»å–æ—§æ•°æ® =================
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, "r", encoding="utf-8") as f:
                old_data = json.load(f)
        except json.JSONDecodeError:
            print("âš ï¸ JSON file corrupted, starting fresh.")
            old_data = []
    else:
        old_data = []
    
    # æå–ç°æœ‰ DOI é›†åˆï¼ˆç»Ÿä¸€è½¬å°å†™ï¼Œé˜²æ­¢å¤§å°å†™å·®å¼‚å¯¼è‡´çš„é‡å¤ï¼‰
    existing_dois = set()
    for item in old_data:
        d = item.get('doi') or item.get('DOI')
        if d:
            existing_dois.add(d.lower().strip())

    print(f"ğŸ“š Existing database has {len(old_data)} entries.")

    # ================= 2. çˆ¬å–æ–°æ•°æ® =================
    # âœ… æ”¹åŠ¨2ï¼šä½¿ç”¨ fetch_broad_probe_papers
    # å»ºè®®è®¾ç½® 3-5 å¤©ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨ç”¨çš„æ˜¯"å½•å…¥æ—¥æœŸ(Entrez Date)"ï¼Œè¿™ä¸ªæ›´æ–°éå¸¸åŠæ—¶
    print("ğŸŒ Fetching data using BROAD strategy (Entrez Date)...")
    try:
        new_papers = fetch_broad_probe_papers(days_back=5)
    except Exception as e:
        print(f"âŒ Critical Error during fetching: {e}")
        return

    print(f"ğŸ“¦ Fetched {len(new_papers)} candidates from PubMed.")

    # ================= 3. ç­›é€‰æœªå¤„ç†çš„ =================
    to_process = []
    for p in new_papers:
        # è·å– DOI å¹¶æ¸…æ´—
        current_doi = p.get('doi') or p.get('DOI')
        if not current_doi:
            continue
            
        clean_doi = current_doi.lower().strip()
        
        # åªæœ‰å½“ DOI ä¸åœ¨åº“ä¸­æ—¶ï¼Œæ‰å¤„ç†
        if clean_doi not in existing_dois:
            to_process.append(p)

    print(f"ğŸ” Found {len(to_process)} NEW papers to analyze (after deduplication).")

    if not to_process:
        print("ğŸ’¤ No new unique papers found. Exiting.")
        return

    # ================= 4. AI åˆ†æ =================
    # æç¤ºï¼šå¦‚æœä¸€æ¬¡æ›´æ–°å¤ªå¤šï¼ˆä¾‹å¦‚ >20 ç¯‡ï¼‰ï¼Œå¯èƒ½éœ€è¦è€ƒè™‘åˆ†æ‰¹è¿è¡Œ
    added_count = 0
    
    print("ğŸ¤– Starting AI Analysis...")
    
    for i, paper in enumerate(to_process):
        title = paper.get('title') or paper.get('Title')
        print(f"   [{i+1}/{len(to_process)}] Analyzing: {title[:50]}...")
        
        # è°ƒç”¨ AI
        result = analyze_one_paper(paper)
        
        # âœ… æ”¹åŠ¨3ï¼šå¢åŠ å»¶æ—¶ï¼Œé˜²æ­¢ API å¹¶å‘è¿‡é«˜æŠ¥é”™
        time.sleep(1.0) 
        
        if result and result.get('is_new'):
            probe_name = result.get('probe_name', 'Unknown')
            print(f"      âœ… NEW PROBE DISCOVERED: {probe_name}")
            
            # åˆå¹¶åŸå§‹æ•°æ®å’Œ AI åˆ†æç»“æœ
            # æ³¨æ„ï¼šä¿ç•™ paper é‡Œçš„ metadataï¼Œç”¨ result è¦†ç›–å…³é”®å­—æ®µ
            merged_entry = {**paper, **result}
            
            # ç¡®ä¿ç»Ÿä¸€çš„å°å†™ key å­˜åœ¨ (ä¸ºäº†å…¼å®¹å‰ç«¯)
            if 'Title' in merged_entry and 'title' not in merged_entry:
                merged_entry['title'] = merged_entry['Title']
            if 'Abstract' in merged_entry and 'abstract' not in merged_entry:
                merged_entry['abstract'] = merged_entry['Abstract']
                
            old_data.append(merged_entry) # åŠ å…¥æ€»è¡¨
            added_count += 1
        else:
            # å¯èƒ½æ˜¯çº¯åº”ç”¨æ–‡ç« ï¼Œæˆ–è€…æ˜¯æå–å¤±è´¥
            print("      âŒ Not a new sensor development.")

    # ================= 5. ä¿å­˜ç»“æœ =================
    if added_count > 0:
        print(f"ğŸ’¾ Saving {added_count} new entries to {DB_FILE}...")
        # å¤‡ä»½ä¸€ä¸‹æ˜¯ä¸ªå¥½ä¹ æƒ¯ï¼ˆå¯é€‰ï¼‰
        # shutil.copy(DB_FILE, DB_FILE + ".bak") 
        
        with open(DB_FILE, "w", encoding="utf-8") as f:
            json.dump(old_data, f, indent=4, ensure_ascii=False)
        print("ğŸ‰ Update Complete!")
    else:
        print("ğŸ Analysis complete, no new probes added to database.")

if __name__ == "__main__":
    main()