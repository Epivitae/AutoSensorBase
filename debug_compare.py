import pandas as pd
from data_fetcher import fetch_recent_papers, fetch_broad_probe_papers

def normalize_doi(doi_url):
    """ç»Ÿä¸€ DOI æ ¼å¼ä»¥ä¾¿å¯¹æ¯” (å»æ‰ http å‰ç¼€ï¼Œè½¬å°å†™)"""
    if not doi_url: return "none"
    # å…¼å®¹æœ‰äº›æ•°æ®å¯èƒ½æ˜¯ float ç±»å‹ (NaN)
    return str(doi_url).lower().replace("https://doi.org/", "").replace("http://doi.org/", "").strip()

def main():
    print("âš”ï¸  å¼€å§‹ A/B æµ‹è¯•ï¼šæ—§çˆ¬è™« vs æ–°çˆ¬è™«")
    days = 30 

    # 1. è¿è¡Œæ—§çˆ¬è™« (å¢åŠ é˜²å¾¡æ€§ä»£ç ï¼šor [])
    print(f"\nğŸ‘´ æ­£åœ¨è¿è¡Œæ—§ç‰ˆ fetch_recent_papers ({days}å¤©)...")
    old_data = fetch_recent_papers(days_back=days) or [] 
    print(f"   -> æ—§ç‰ˆæ•è·: {len(old_data)} ç¯‡")

    # 2. è¿è¡Œæ–°çˆ¬è™« (å¢åŠ é˜²å¾¡æ€§ä»£ç ï¼šor [])
    print(f"\nğŸ‘¶ æ­£åœ¨è¿è¡Œæ–°ç‰ˆ fetch_broad_probe_papers ({days}å¤©)...")
    new_data = fetch_broad_probe_papers(days_back=days) or []
    print(f"   -> æ–°ç‰ˆæ•è·: {len(new_data)} ç¯‡")

    # 3. æ•°æ®å¤„ç†ä¸å¯¹æ¯”
    old_dois = {normalize_doi(p.get('doi')) for p in old_data}
    
    # æ–°ç‰ˆå¯èƒ½ç”¨å¤§å†™ DOI æˆ–å°å†™ doiï¼Œåšä¸ªå…¼å®¹
    new_dois = set()
    for p in new_data:
        d = p.get('DOI') or p.get('doi')
        new_dois.add(normalize_doi(d))

    # é›†åˆè¿ç®—
    common = old_dois & new_dois         
    only_in_new = new_dois - old_dois    
    only_in_old = old_dois - new_dois    

    # 4. è¾“å‡ºåˆ†ææŠ¥å‘Š
    print("\n" + "="*40)
    print("ğŸ“Š  å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    print("="*40)
    print(f"âœ… å…±åŒæ•è·: {len(common)} ç¯‡")
    print(f"ğŸš€ æ–°ç‰ˆæ–°å¢ (ç‹¬æœ‰): {len(only_in_new)} ç¯‡")
    print(f"âš ï¸ æ—§ç‰ˆç‹¬æœ‰ (æ–°ç‰ˆæ¼æŠ“): {len(only_in_old)} ç¯‡")

    # 5. å±•ç¤ºæ–°ç‰ˆå¤šæŠ“åˆ°äº†ä»€ä¹ˆ
    if only_in_new:
        print("\nğŸ” æ–°ç‰ˆé¢å¤–å‘ç°çš„é«˜ä»·å€¼è®ºæ–‡ (ç¤ºä¾‹å‰ 5 ç¯‡):")
        count = 0
        for p in new_data:
            d_norm = normalize_doi(p.get('DOI') or p.get('doi'))
            if d_norm in only_in_new:
                # æ‰“å°æ ‡é¢˜å’Œæ˜¯å¦åƒå¼€å‘ç±»
                is_dev = p.get('Is_Development_Likely', '')
                # å…¼å®¹æ—§ç‰ˆ title å°å†™
                title = p.get('Title') or p.get('title')
                print(f"   [{is_dev}] {title}")
                count += 1
                if count >= 5: break
    
    # 6. æ£€æŸ¥æ˜¯å¦æœ‰â€œå€’é€€â€
    if only_in_old:
        print("\nğŸš¨ è­¦å‘Šï¼šæ–°ç‰ˆæ¼æ‰äº†æ—§ç‰ˆèƒ½æŠ“åˆ°çš„è®ºæ–‡ (éœ€æ£€æŸ¥åŸå› ):")
        for p in old_data:
            d_norm = normalize_doi(p.get('doi'))
            if d_norm in only_in_old:
                title = p.get('Title') or p.get('title')
                print(f"   - {title}")

if __name__ == "__main__":
    main()