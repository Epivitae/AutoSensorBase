import json
import os
from data_fetcher import fetch_papers_by_date_range

RAW_FILE = "raw_papers.json"

def main():
    # ===åœ¨æ­¤å¤„ä¿®æ”¹ä½ æƒ³æŠ“å–çš„æ—¥æœŸèŒƒå›´===
    TARGET_START = "2010/01/01"
    TARGET_END = "2019/12/31"
    # ===============================

    print(f"ğŸš€ æ‰‹åŠ¨æŠ“å–æ¨¡å¼: {TARGET_START} è‡³ {TARGET_END}")

    # 1. è¯»å–ç°æœ‰çš„ Raw æ•°æ® (ç”¨äºå»é‡)
    if os.path.exists(RAW_FILE):
        with open(RAW_FILE, "r", encoding="utf-8") as f:
            raw_data = json.load(f)
    else:
        raw_data = []

    # å»ºç«‹ DOI ç´¢å¼•
    existing_dois = set()
    for item in raw_data:
        d = item.get('doi')
        if d: existing_dois.add(d.lower().strip().replace("https://doi.org/", ""))
    
    print(f"ğŸ“š æœ¬åœ°å·²æœ‰ Raw æ–‡çŒ®: {len(raw_data)} ç¯‡")

    # 2. æ‰§è¡ŒæŠ“å–
    new_candidates = fetch_papers_by_date_range(TARGET_START, TARGET_END)
    
    # 3. å…¥åº“ (Deduplication & Staging)
    added_count = 0
    for p in new_candidates:
        clean_doi = p['doi'].lower().strip().replace("https://doi.org/", "")
        
        # åªæœ‰å½“ DOI ä¸å­˜åœ¨æ—¶æ‰æ·»åŠ 
        if clean_doi not in existing_dois:
            # åˆå§‹åŒ–çŠ¶æ€
            p['ai_analyzed'] = False 
            p['is_probe'] = False
            
            raw_data.append(p)
            existing_dois.add(clean_doi)
            added_count += 1
    
    # 4. ä¿å­˜
    if added_count > 0:
        with open(RAW_FILE, "w", encoding="utf-8") as f:
            json.dump(raw_data, f, indent=4, ensure_ascii=False)
        print(f"\nâœ… æˆåŠŸæ·»åŠ  {added_count} ç¯‡æ–°æ–‡çŒ®åˆ° {RAW_FILE}ï¼")
        print("ğŸ’¡ ä¸‹ä¸€æ­¥: è¯·è¿è¡Œ python update_daily.py å¼€å§‹ AI åˆ†æã€‚")
    else:
        print("\nğŸ’¤ æ²¡æœ‰å‘ç°æ–°æ–‡çŒ® (æ‰€æœ‰æŠ“å–åˆ°çš„éƒ½åœ¨åº“é‡Œäº†)ã€‚")

if __name__ == "__main__":
    main()